{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDYXmdzfgc4P"
      },
      "source": [
        "### Using Whisper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQqLGHLl_l49",
        "outputId": "5cfcdbf4-0a95-4590-8385-ce41af458ea6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " After reading tons of productivity books, I came across so many rules. Like the two-year rule, the five-minute rule, the five-second rule. No, not that five-second rule. The problem is that these rules are meant for companies or entrepreneurs. But I was able to adapt them to my studies during med school and drastically cut down on my procrastination. So I'm going to share with you two different two-minute rules for the next two minutes. The first two-minute rule comes from getting things done by David Allen. He says, if it takes two minutes to do, get it done right now. For example, if I need to take out the trash today, it takes two minutes to do. So if I'm thinking about it now, I might as well just do it now. Instead of writing it down on a to-do list or probably forgetting about it or having to come back to it later, which takes more than two minutes. That's how I see it. So here's a list of things that might take two minutes throughout the day, like organizing your desk or watering your plants or clipping those nasty nails. I just do it when I notice it, but these little things start to add up. So this rule biases my brain towards taking action and away from procrastination. The second two-minute rule comes from Atomic Habits by James Clear. He says, when you're trying to do something you don't really want to do, simplify the task down to two minutes or less. So doing your entire reading assignment becomes just reading one paragraph or memorizing the entire periodic table becomes memorizing just 10 flashcards. Now, some of you might think, yeah, this is just a Jedi mind trick. Like, why would I fall for it? How is this at all sustainable? And to that, he says, when you're starting out, limit yourself to only two minutes. So back in med school, I wanted to build a habit of studying for one hour every day before dinner. So I tried this trick, but I lived in myself to just two minutes. I'd sit down, open my laptop, study for two minutes, and then close my laptop and went to do something else. It seems unproductive at first, right? It seems stupid. But staying consistent with this two-minute routine day after day meant that I was becoming the type of person who studies daily. I was mastering the habit of just showing up because a habit needs to be established before it can be expanded on. If I can't become a person who studies for just two minutes a day, I'd never be able to become the person that studies for an hour a day. You've got to start somewhere, but starting small is easier. There's a lot of other useful tips from books. I cover more here in this video on three books and three minutes. Check it out. And if you guys like these types of videos, let me know in the comments below. I'll see you there. Bye.\n"
          ]
        }
      ],
      "source": [
        "import whisper\n",
        "import torch\n",
        "import os\n",
        "\n",
        "def transcribe_audio(audio_path, model_size='base', language='en'):\n",
        "\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    model = whisper.load_model(model_size).to(device)\n",
        "    result = model.transcribe(audio_path, language=language)\n",
        "    return result['text']\n",
        "\n",
        "audio_file = \"output.mp3\"\n",
        "transcribed_text = transcribe_audio(audio_file)\n",
        "\n",
        "print(transcribed_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3NUdh6fAIbN",
        "outputId": "91476bd3-a493-4d57-a51b-7ab7d6040296"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.00 - 2.16]  If  you  have  trouble  speaking  on  the  spot,\n",
            "[2.34 - 4.74]  you  have  nothing  prepared,  try  this  format.\n",
            "[5.12 - 6.52]  It's  called  the  prep  format.\n",
            "[6.92 - 9.52]  You  make  your  point,  you  provide  a  reason\n",
            "[9.52 - 11.96]  why  you  chose  that,  you  give  an  example,\n",
            "[11.96 - 13.50]  and  then  you  make  a  point  again.\n",
            "[14.04 - 15.82]  So  here's  an  example  of  this.\n",
            "[16.16 - 18.80]  Let's  say  the  question  was,  what  is  your  favorite  fruit?\n",
            "[19.34 - 20.88]  You're  not  prepared  to  answer  that  question,\n",
            "[20.98 - 22.48]  but  if  you  were  to  do  it,  you  could  say\n",
            "[22.48 - 22.72]  something\n",
            "[22.72 - 25.14]  like  my  favorite  fruit  is  the  banana.\n",
            "[25.78 - 28.32]  The  reason  I  like  it  is  because  it  tastes  really\n",
            "[28.32 - 28.48]  good\n",
            "[28.48 - 29.54]  in  my  protein  shakes.\n",
            "[30.04 - 33.30]  For  example,  when  I  came  back  from  the  gym  yesterday,\n",
            "[33.64 - 35.94]  I  want  something  to  eat  or  drink  quickly,\n",
            "[36.10 - 38.36]  so  I  always  put  a  banana  in  my  protein  shake\n",
            "[38.36 - 39.54]  and  I  drink  it  right  afterwards.\n",
            "[39.94 - 42.34]  That's  why  bananas  are  my  favorite  fruit.\n",
            "[{'start': np.float64(0.0), 'end': np.float64(2.16), 'text': ' If  you  have  trouble  speaking  on  the  spot,'}, {'start': np.float64(2.34), 'end': np.float64(4.74), 'text': ' you  have  nothing  prepared,  try  this  format.'}, {'start': np.float64(5.12), 'end': np.float64(6.52), 'text': \" It's  called  the  prep  format.\"}, {'start': np.float64(6.92), 'end': np.float64(9.52), 'text': ' You  make  your  point,  you  provide  a  reason'}, {'start': np.float64(9.52), 'end': np.float64(11.96), 'text': ' why  you  chose  that,  you  give  an  example,'}, {'start': np.float64(11.96), 'end': np.float64(13.5), 'text': ' and  then  you  make  a  point  again.'}, {'start': np.float64(14.04), 'end': np.float64(15.82), 'text': \" So  here's  an  example  of  this.\"}, {'start': np.float64(16.16), 'end': np.float64(18.8), 'text': \" Let's  say  the  question  was,  what  is  your  favorite  fruit?\"}, {'start': np.float64(19.34), 'end': np.float64(20.88), 'text': \" You're  not  prepared  to  answer  that  question,\"}, {'start': np.float64(20.98), 'end': np.float64(22.48), 'text': ' but  if  you  were  to  do  it,  you  could  say'}, {'start': np.float64(22.48), 'end': np.float64(22.72), 'text': ' something'}, {'start': np.float64(22.72), 'end': np.float64(25.14), 'text': ' like  my  favorite  fruit  is  the  banana.'}, {'start': np.float64(25.78), 'end': np.float64(28.32), 'text': ' The  reason  I  like  it  is  because  it  tastes  really'}, {'start': np.float64(28.32), 'end': np.float64(28.48), 'text': ' good'}, {'start': np.float64(28.48), 'end': np.float64(29.54), 'text': ' in  my  protein  shakes.'}, {'start': np.float64(30.04), 'end': np.float64(33.3), 'text': ' For  example,  when  I  came  back  from  the  gym  yesterday,'}, {'start': np.float64(33.64), 'end': np.float64(35.94), 'text': ' I  want  something  to  eat  or  drink  quickly,'}, {'start': np.float64(36.1), 'end': np.float64(38.36), 'text': ' so  I  always  put  a  banana  in  my  protein  shake'}, {'start': np.float64(38.36), 'end': np.float64(39.54), 'text': ' and  I  drink  it  right  afterwards.'}, {'start': np.float64(39.94), 'end': np.float64(42.34), 'text': \" That's  why  bananas  are  my  favorite  fruit.\"}]\n"
          ]
        }
      ],
      "source": [
        "import whisper\n",
        "import torch\n",
        "import os\n",
        "\n",
        "def transcribe_audio_with_subtitle_timestamps(audio_path, model_size='base', language='en', words_per_subtitle=10):\n",
        "    \"\"\"Transcribes audio with subtitles (groups of words) and timestamps for all segments.\"\"\"\n",
        "\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    model = whisper.load_model(model_size).to(device)\n",
        "    result = model.transcribe(audio_path, language=language, word_timestamps=True)\n",
        "    segments = result['segments']  # Get all segments\n",
        "\n",
        "    all_subtitles = []\n",
        "\n",
        "    for segment in segments:  # Iterate through each segment\n",
        "        words = segment['words']\n",
        "        subtitles = []\n",
        "        current_subtitle = []\n",
        "        current_start = None\n",
        "        last_end = None\n",
        "\n",
        "        for word_info in words:\n",
        "            word = word_info['word']\n",
        "            start = word_info['start']\n",
        "            end = word_info['end']\n",
        "\n",
        "            if current_start is None:\n",
        "                current_start = start\n",
        "\n",
        "            current_subtitle.append(word)\n",
        "\n",
        "            if len(current_subtitle) >= words_per_subtitle:\n",
        "                subtitle_text = \" \".join(current_subtitle)\n",
        "                subtitles.append({'start': current_start, 'end': end, 'text': subtitle_text})\n",
        "                current_subtitle = []\n",
        "                current_start = None\n",
        "\n",
        "            last_end = end\n",
        "\n",
        "        # Handle remaining words in the segment\n",
        "        if current_subtitle:\n",
        "            subtitle_text = \" \".join(current_subtitle)\n",
        "            subtitles.append({'start': current_start, 'end': last_end, 'text': subtitle_text})\n",
        "\n",
        "        all_subtitles.extend(subtitles) # Add the subtitles from this segment to the complete list.\n",
        "\n",
        "    return all_subtitles\n",
        "\n",
        "audio_file = \"test.mp3\"  # Replace with your audio file\n",
        "subtitles = transcribe_audio_with_subtitle_timestamps(audio_file)\n",
        "\n",
        "if subtitles:\n",
        "    for subtitle in subtitles:\n",
        "        print(f\"[{subtitle['start']:.2f} - {subtitle['end']:.2f}] {subtitle['text']}\")\n",
        "else:\n",
        "    print(\"Transcription failed.\")\n",
        "\n",
        "print(subtitles)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUZSgoYGBCcU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMDhkrx1giYr"
      },
      "source": [
        "### Subtitle Macker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vxHQ-l43ihgq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai-whisper in c:\\users\\vignesh\\anaconda3\\lib\\site-packages (20240930)\n",
            "Requirement already satisfied: numba in c:\\users\\vignesh\\anaconda3\\lib\\site-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\vignesh\\anaconda3\\lib\\site-packages (from openai-whisper) (1.26.4)\n",
            "Requirement already satisfied: torch in c:\\users\\vignesh\\anaconda3\\lib\\site-packages (from openai-whisper) (2.5.1)\n",
            "Requirement already satisfied: tqdm in c:\\users\\vignesh\\anaconda3\\lib\\site-packages (from openai-whisper) (4.66.5)\n",
            "Requirement already satisfied: more-itertools in c:\\users\\vignesh\\anaconda3\\lib\\site-packages (from openai-whisper) (10.3.0)\n",
            "Requirement already satisfied: tiktoken in c:\\users\\vignesh\\anaconda3\\lib\\site-packages (from openai-whisper) (0.9.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\vignesh\\anaconda3\\lib\\site-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\vignesh\\anaconda3\\lib\\site-packages (from tiktoken->openai-whisper) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in c:\\users\\vignesh\\anaconda3\\lib\\site-packages (from tiktoken->openai-whisper) (2.32.3)\n",
            "Requirement already satisfied: filelock in c:\\users\\vignesh\\anaconda3\\lib\\site-packages (from torch->openai-whisper) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\vignesh\\anaconda3\\lib\\site-packages (from torch->openai-whisper) (4.11.0)\n",
            "Requirement already satisfied: setuptools in c:\\users\\vignesh\\anaconda3\\lib\\site-packages (from torch->openai-whisper) (75.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in c:\\users\\vignesh\\anaconda3\\lib\\site-packages (from torch->openai-whisper) (1.13.1)\n",
            "Requirement already satisfied: networkx in c:\\users\\vignesh\\anaconda3\\lib\\site-packages (from torch->openai-whisper) (3.3)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\vignesh\\anaconda3\\lib\\site-packages (from torch->openai-whisper) (3.1.4)\n",
            "Requirement already satisfied: fsspec in c:\\users\\vignesh\\anaconda3\\lib\\site-packages (from torch->openai-whisper) (2024.6.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\vignesh\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\vignesh\\anaconda3\\lib\\site-packages (from tqdm->openai-whisper) (0.4.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vignesh\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vignesh\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vignesh\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vignesh\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\vignesh\\anaconda3\\lib\\site-packages (from jinja2->torch->openai-whisper) (2.1.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai-whisper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting moviepy\n",
            "  Downloading moviepy-2.1.2-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: decorator<6.0,>=4.0.2 in c:\\users\\vignesh\\anaconda3\\lib\\site-packages (from moviepy) (5.1.1)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in c:\\users\\vignesh\\anaconda3\\lib\\site-packages (from moviepy) (2.33.1)\n",
            "Collecting imageio_ffmpeg>=0.2.0 (from moviepy)\n",
            "  Downloading imageio_ffmpeg-0.6.0-py3-none-win_amd64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: numpy>=1.25.0 in c:\\users\\vignesh\\anaconda3\\lib\\site-packages (from moviepy) (1.26.4)\n",
            "Collecting proglog<=1.0.0 (from moviepy)\n",
            "  Downloading proglog-0.1.11-py3-none-any.whl.metadata (794 bytes)\n",
            "Requirement already satisfied: python-dotenv>=0.10 in c:\\users\\vignesh\\anaconda3\\lib\\site-packages (from moviepy) (0.21.0)\n",
            "Requirement already satisfied: pillow<11.0,>=9.2.0 in c:\\users\\vignesh\\anaconda3\\lib\\site-packages (from moviepy) (10.4.0)\n",
            "Requirement already satisfied: tqdm in c:\\users\\vignesh\\anaconda3\\lib\\site-packages (from proglog<=1.0.0->moviepy) (4.66.5)\n",
            "Requirement already satisfied: colorama in c:\\users\\vignesh\\anaconda3\\lib\\site-packages (from tqdm->proglog<=1.0.0->moviepy) (0.4.6)\n",
            "Downloading moviepy-2.1.2-py3-none-any.whl (126 kB)\n",
            "Downloading imageio_ffmpeg-0.6.0-py3-none-win_amd64.whl (31.2 MB)\n",
            "   ---------------------------------------- 0.0/31.2 MB ? eta -:--:--\n",
            "   ----- ---------------------------------- 4.5/31.2 MB 22.4 MB/s eta 0:00:02\n",
            "   --------------- ------------------------ 11.8/31.2 MB 29.6 MB/s eta 0:00:01\n",
            "   --------------- ------------------------ 12.3/31.2 MB 29.7 MB/s eta 0:00:01\n",
            "   ---------------- ----------------------- 13.1/31.2 MB 16.1 MB/s eta 0:00:02\n",
            "   ------------------- -------------------- 15.5/31.2 MB 14.5 MB/s eta 0:00:02\n",
            "   ------------------------ --------------- 18.9/31.2 MB 14.7 MB/s eta 0:00:01\n",
            "   ----------------------------- ---------- 23.1/31.2 MB 15.4 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 24.6/31.2 MB 14.5 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 26.2/31.2 MB 13.7 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 28.6/31.2 MB 13.3 MB/s eta 0:00:01\n",
            "   ---------------------------------------  31.2/31.2 MB 13.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 31.2/31.2 MB 13.0 MB/s eta 0:00:00\n",
            "Downloading proglog-0.1.11-py3-none-any.whl (7.8 kB)\n",
            "Installing collected packages: imageio_ffmpeg, proglog, moviepy\n",
            "Successfully installed imageio_ffmpeg-0.6.0 moviepy-2.1.2 proglog-0.1.11\n"
          ]
        }
      ],
      "source": [
        "!pip install moviepy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Urutrv7MiKu8",
        "outputId": "cec844e6-943c-4d73-c172-a86fc5588cd2"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'moviepy.editor'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[5], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Video to Audio COnverter\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmoviepy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meditor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VideoFileClip\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_video_to_audio\u001b[39m(video_path, audio_path):\n\u001b[0;32m      6\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'moviepy.editor'"
          ]
        }
      ],
      "source": [
        "# Video to Audio COnverter\n",
        "\n",
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "def convert_video_to_audio(video_path, audio_path):\n",
        "  try:\n",
        "    video_clip = VideoFileClip(video_path)\n",
        "    audio_clip = video_clip.audio\n",
        "    audio_clip.write_audiofile(audio_path)\n",
        "    video_clip.close()\n",
        "    audio_clip.close()\n",
        "    print(f\"Succesfully converted {video_path} to {audio_path}\")\n",
        "  except Exception as e:\n",
        "    print(f\"Error: {e}\")\n",
        "\n",
        "video_path = 'vtest.mp4'\n",
        "audio_path = 'output.mp3'\n",
        "convert_video_to_audio(video_path, audio_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Nd7cd4jglYf",
        "outputId": "a7a3483e-ac43-46e1-8f56-2fec8f7e5c88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'start': np.float64(0.0), 'end': np.float64(2.7), 'text': ' After  reading  tons  of  productivity  books,  I  came  across  so'}, {'start': np.float64(2.7), 'end': np.float64(3.38), 'text': ' many  rules.'}, {'start': np.float64(3.8), 'end': np.float64(6.36), 'text': ' Like  the  two -year  rule,  the  five -minute  rule,  the'}, {'start': np.float64(6.36), 'end': np.float64(7.48), 'text': ' five -second  rule.'}, {'start': np.float64(7.68), 'end': np.float64(9.22), 'text': ' No,  not  that  five -second  rule.'}, {'start': np.float64(9.34), 'end': np.float64(11.6), 'text': ' The  problem  is  that  these  rules  are  meant  for  companies'}, {'start': np.float64(11.6), 'end': np.float64(12.66), 'text': ' or  entrepreneurs.'}, {'start': np.float64(13.16), 'end': np.float64(15.38), 'text': ' But  I  was  able  to  adapt  them  to  my  studies'}, {'start': np.float64(15.38), 'end': np.float64(16.32), 'text': ' during  med  school'}, {'start': np.float64(16.32), 'end': np.float64(18.6), 'text': ' and  drastically  cut  down  on  my  procrastination.'}, {'start': np.float64(18.84), 'end': np.float64(20.88), 'text': \" So  I'm  going  to  share  with  you  two  different  two\"}, {'start': np.float64(20.88), 'end': np.float64(22.98), 'text': '-minute  rules  for  the  next  two  minutes.'}, {'start': np.float64(23.48), 'end': np.float64(25.56), 'text': ' The  first  two -minute  rule  comes  from  getting  things  done'}, {'start': np.float64(25.56), 'end': np.float64(26.36), 'text': ' by  David  Allen.'}, {'start': np.float64(26.36), 'end': np.float64(28.76), 'text': ' He  says,  if  it  takes  two  minutes  to  do,  get'}, {'start': np.float64(28.76), 'end': np.float64(29.78), 'text': ' it  done  right  now.'}, {'start': np.float64(30.06), 'end': np.float64(31.78), 'text': ' For  example,  if  I  need  to  take  out  the  trash'}, {'start': np.float64(31.78), 'end': np.float64(33.48), 'text': ' today,  it  takes  two  minutes  to  do.'}, {'start': np.float64(33.8), 'end': np.float64(35.9), 'text': \" So  if  I'm  thinking  about  it  now,  it  might  as\"}, {'start': np.float64(35.9), 'end': np.float64(36.66), 'text': ' well  just  do  it  now.'}, {'start': np.float64(36.98), 'end': np.float64(39.6), 'text': ' Instead  of  writing  it  down  on  a  to -do  list'}, {'start': np.float64(39.6), 'end': np.float64(40.86), 'text': ' or  probably  forgetting  about  it'}, {'start': np.float64(40.86), 'end': np.float64(43.1), 'text': ' or  having  to  come  back  to  it  later,  which  takes'}, {'start': np.float64(43.1), 'end': np.float64(44.16), 'text': ' more  than  two  minutes.'}, {'start': np.float64(44.52), 'end': np.float64(45.34), 'text': \" That's  how  I  see  it.\"}, {'start': np.float64(45.42), 'end': np.float64(47.38), 'text': \" So  here's  a  list  of  things  that  might  take  two\"}, {'start': np.float64(47.38), 'end': np.float64(48.58), 'text': ' minutes  throughout  the  day,'}, {'start': np.float64(48.76), 'end': np.float64(51.96), 'text': ' like  organizing  your  desk  or  watering  your  plants  or  clipping'}, {'start': np.float64(51.96), 'end': np.float64(53.26), 'text': ' those  nasty  nails.'}, {'start': np.float64(53.26), 'end': np.float64(55.22), 'text': ' I  just  do  it  when  I  notice  it,  but  these'}, {'start': np.float64(55.22), 'end': np.float64(56.36), 'text': ' little  things  start  to  add  up.'}, {'start': np.float64(56.48), 'end': np.float64(59.76), 'text': ' So  this  rule  biases  my  brain  towards  taking  action  and'}, {'start': np.float64(59.76), 'end': np.float64(61.26), 'text': ' away  from  procrastination.'}, {'start': np.float64(61.42), 'end': np.float64(63.48), 'text': ' The  second  two -minute  rule  comes  from  Atomic  Habits  by'}, {'start': np.float64(63.48), 'end': np.float64(64.04), 'text': ' James  Clear.'}, {'start': np.float64(64.34), 'end': np.float64(66.16), 'text': \" He  says,  when  you're  trying  to  do  something  you  don't\"}, {'start': np.float64(66.16), 'end': np.float64(67.08), 'text': ' really  want  to  do,'}, {'start': np.float64(67.24), 'end': np.float64(69.4), 'text': ' simplify  the  task  down  to  two  minutes  or  less.'}, {'start': np.float64(69.74), 'end': np.float64(72.48), 'text': ' So  doing  your  entire  reading  assignment  becomes  just  reading  one'}, {'start': np.float64(72.48), 'end': np.float64(73.0), 'text': ' paragraph'}, {'start': np.float64(73.0), 'end': np.float64(77.62), 'text': ' or  memorizing  the  entire  periodic  table  becomes  memorizing  just  10'}, {'start': np.float64(77.62), 'end': np.float64(78.22), 'text': ' flashcards.'}, {'start': np.float64(78.52), 'end': np.float64(81.12), 'text': ' Now,  some  of  you  might  think,  yeah,  this  is  just'}, {'start': np.float64(81.12), 'end': np.float64(82.36), 'text': ' a  Jedi  mind  trick.'}, {'start': np.float64(82.36), 'end': np.float64(83.82), 'text': ' Like,  why  would  I  fall  for  it?'}, {'start': np.float64(84.04), 'end': np.float64(85.64), 'text': ' How  is  this  at  all  sustainable?'}, {'start': np.float64(86.22), 'end': np.float64(88.46), 'text': \" And  to  that,  he  says,  when  you're  starting  out,\"}, {'start': np.float64(88.7), 'end': np.float64(90.8), 'text': ' limit  yourself  to  only  two  minutes.'}, {'start': np.float64(91.16), 'end': np.float64(93.04), 'text': ' So  back  in  med  school,  I  wanted  to  build  a'}, {'start': np.float64(93.04), 'end': np.float64(96.06), 'text': ' habit  of  studying  for  one  hour  every  day  before  dinner.'}, {'start': np.float64(96.48), 'end': np.float64(99.02), 'text': ' So  I  tried  this  trick,  but  I  lived  in  myself'}, {'start': np.float64(99.02), 'end': np.float64(100.5), 'text': ' to  just  two  minutes.'}, {'start': np.float64(100.86), 'end': np.float64(103.84), 'text': \" I'd  sit  down,  open  my  laptop,  study  for  two  minutes,\"}, {'start': np.float64(104.12), 'end': np.float64(106.1), 'text': ' and  then  close  my  laptop  and  went  to  do  something'}, {'start': np.float64(106.1), 'end': np.float64(106.34), 'text': ' else.'}, {'start': np.float64(106.56), 'end': np.float64(108.68), 'text': ' It  seems  unproductive  at  first,  right?'}, {'start': np.float64(108.78), 'end': np.float64(109.42), 'text': ' It  seems  stupid.'}, {'start': np.float64(109.42), 'end': np.float64(113.02), 'text': ' But  staying  consistent  with  this  two -minute  routine  day  after'}, {'start': np.float64(113.02), 'end': np.float64(114.96), 'text': ' day  meant  that  I  was  becoming'}, {'start': np.float64(114.96), 'end': np.float64(117.2), 'text': ' the  type  of  person  who  studies  daily.'}, {'start': np.float64(117.46), 'end': np.float64(120.34), 'text': ' I  was  mastering  the  habit  of  just  showing  up,'}, {'start': np.float64(120.48), 'end': np.float64(124.04), 'text': ' because  a  habit  needs  to  be  established  before  it  can'}, {'start': np.float64(124.04), 'end': np.float64(124.88), 'text': ' be  expanded  on.'}, {'start': np.float64(125.18), 'end': np.float64(127.32), 'text': \" If  I  can't  become  a  person  who  studies  for  just\"}, {'start': np.float64(127.32), 'end': np.float64(128.52), 'text': ' two  minutes  a  day,'}, {'start': np.float64(128.7), 'end': np.float64(131.38), 'text': \" I'd  never  be  able  to  become  the  person  that  studies\"}, {'start': np.float64(131.38), 'end': np.float64(132.34), 'text': ' for  an  hour  a  day.'}, {'start': np.float64(132.7), 'end': np.float64(135.52), 'text': \" You've  got  to  start  somewhere,  but  starting  small  is  easier.\"}, {'start': np.float64(135.66), 'end': np.float64(137.92), 'text': \" There's  a  lot  of  other  useful  tips  from  books.\"}, {'start': np.float64(137.92), 'end': np.float64(140.56), 'text': ' I  cover  more  here  in  this  video  on  three  books'}, {'start': np.float64(140.56), 'end': np.float64(141.2), 'text': ' and  three  minutes.'}, {'start': np.float64(141.5), 'end': np.float64(142.18), 'text': ' Check  it  out.'}, {'start': np.float64(142.32), 'end': np.float64(143.96), 'text': ' If  you  guys  like  these  types  of  videos,  let  me'}, {'start': np.float64(143.96), 'end': np.float64(144.88), 'text': ' know  in  the  comments  below.'}, {'start': np.float64(145.28), 'end': np.float64(145.82), 'text': \" I'll  see  you  there.\"}, {'start': np.float64(146.1), 'end': np.float64(146.34), 'text': ' Bye.'}]\n",
            "[0.00 - 2.70]  After  reading  tons  of  productivity  books,  I  came  across  so\n",
            "[2.70 - 3.38]  many  rules.\n",
            "[3.80 - 6.36]  Like  the  two -year  rule,  the  five -minute  rule,  the\n",
            "[6.36 - 7.48]  five -second  rule.\n",
            "[7.68 - 9.22]  No,  not  that  five -second  rule.\n",
            "[9.34 - 11.60]  The  problem  is  that  these  rules  are  meant  for  companies\n",
            "[11.60 - 12.66]  or  entrepreneurs.\n",
            "[13.16 - 15.38]  But  I  was  able  to  adapt  them  to  my  studies\n",
            "[15.38 - 16.32]  during  med  school\n",
            "[16.32 - 18.60]  and  drastically  cut  down  on  my  procrastination.\n",
            "[18.84 - 20.88]  So  I'm  going  to  share  with  you  two  different  two\n",
            "[20.88 - 22.98] -minute  rules  for  the  next  two  minutes.\n",
            "[23.48 - 25.56]  The  first  two -minute  rule  comes  from  getting  things  done\n",
            "[25.56 - 26.36]  by  David  Allen.\n",
            "[26.36 - 28.76]  He  says,  if  it  takes  two  minutes  to  do,  get\n",
            "[28.76 - 29.78]  it  done  right  now.\n",
            "[30.06 - 31.78]  For  example,  if  I  need  to  take  out  the  trash\n",
            "[31.78 - 33.48]  today,  it  takes  two  minutes  to  do.\n",
            "[33.80 - 35.90]  So  if  I'm  thinking  about  it  now,  it  might  as\n",
            "[35.90 - 36.66]  well  just  do  it  now.\n",
            "[36.98 - 39.60]  Instead  of  writing  it  down  on  a  to -do  list\n",
            "[39.60 - 40.86]  or  probably  forgetting  about  it\n",
            "[40.86 - 43.10]  or  having  to  come  back  to  it  later,  which  takes\n",
            "[43.10 - 44.16]  more  than  two  minutes.\n",
            "[44.52 - 45.34]  That's  how  I  see  it.\n",
            "[45.42 - 47.38]  So  here's  a  list  of  things  that  might  take  two\n",
            "[47.38 - 48.58]  minutes  throughout  the  day,\n",
            "[48.76 - 51.96]  like  organizing  your  desk  or  watering  your  plants  or  clipping\n",
            "[51.96 - 53.26]  those  nasty  nails.\n",
            "[53.26 - 55.22]  I  just  do  it  when  I  notice  it,  but  these\n",
            "[55.22 - 56.36]  little  things  start  to  add  up.\n",
            "[56.48 - 59.76]  So  this  rule  biases  my  brain  towards  taking  action  and\n",
            "[59.76 - 61.26]  away  from  procrastination.\n",
            "[61.42 - 63.48]  The  second  two -minute  rule  comes  from  Atomic  Habits  by\n",
            "[63.48 - 64.04]  James  Clear.\n",
            "[64.34 - 66.16]  He  says,  when  you're  trying  to  do  something  you  don't\n",
            "[66.16 - 67.08]  really  want  to  do,\n",
            "[67.24 - 69.40]  simplify  the  task  down  to  two  minutes  or  less.\n",
            "[69.74 - 72.48]  So  doing  your  entire  reading  assignment  becomes  just  reading  one\n",
            "[72.48 - 73.00]  paragraph\n",
            "[73.00 - 77.62]  or  memorizing  the  entire  periodic  table  becomes  memorizing  just  10\n",
            "[77.62 - 78.22]  flashcards.\n",
            "[78.52 - 81.12]  Now,  some  of  you  might  think,  yeah,  this  is  just\n",
            "[81.12 - 82.36]  a  Jedi  mind  trick.\n",
            "[82.36 - 83.82]  Like,  why  would  I  fall  for  it?\n",
            "[84.04 - 85.64]  How  is  this  at  all  sustainable?\n",
            "[86.22 - 88.46]  And  to  that,  he  says,  when  you're  starting  out,\n",
            "[88.70 - 90.80]  limit  yourself  to  only  two  minutes.\n",
            "[91.16 - 93.04]  So  back  in  med  school,  I  wanted  to  build  a\n",
            "[93.04 - 96.06]  habit  of  studying  for  one  hour  every  day  before  dinner.\n",
            "[96.48 - 99.02]  So  I  tried  this  trick,  but  I  lived  in  myself\n",
            "[99.02 - 100.50]  to  just  two  minutes.\n",
            "[100.86 - 103.84]  I'd  sit  down,  open  my  laptop,  study  for  two  minutes,\n",
            "[104.12 - 106.10]  and  then  close  my  laptop  and  went  to  do  something\n",
            "[106.10 - 106.34]  else.\n",
            "[106.56 - 108.68]  It  seems  unproductive  at  first,  right?\n",
            "[108.78 - 109.42]  It  seems  stupid.\n",
            "[109.42 - 113.02]  But  staying  consistent  with  this  two -minute  routine  day  after\n",
            "[113.02 - 114.96]  day  meant  that  I  was  becoming\n",
            "[114.96 - 117.20]  the  type  of  person  who  studies  daily.\n",
            "[117.46 - 120.34]  I  was  mastering  the  habit  of  just  showing  up,\n",
            "[120.48 - 124.04]  because  a  habit  needs  to  be  established  before  it  can\n",
            "[124.04 - 124.88]  be  expanded  on.\n",
            "[125.18 - 127.32]  If  I  can't  become  a  person  who  studies  for  just\n",
            "[127.32 - 128.52]  two  minutes  a  day,\n",
            "[128.70 - 131.38]  I'd  never  be  able  to  become  the  person  that  studies\n",
            "[131.38 - 132.34]  for  an  hour  a  day.\n",
            "[132.70 - 135.52]  You've  got  to  start  somewhere,  but  starting  small  is  easier.\n",
            "[135.66 - 137.92]  There's  a  lot  of  other  useful  tips  from  books.\n",
            "[137.92 - 140.56]  I  cover  more  here  in  this  video  on  three  books\n",
            "[140.56 - 141.20]  and  three  minutes.\n",
            "[141.50 - 142.18]  Check  it  out.\n",
            "[142.32 - 143.96]  If  you  guys  like  these  types  of  videos,  let  me\n",
            "[143.96 - 144.88]  know  in  the  comments  below.\n",
            "[145.28 - 145.82]  I'll  see  you  there.\n",
            "[146.10 - 146.34]  Bye.\n"
          ]
        }
      ],
      "source": [
        "import whisper\n",
        "import torch\n",
        "import os\n",
        "\n",
        "def subtitle_and_timestamps(audio_path, model_size='base', language='en', words_per_subtitle=10):\n",
        "\n",
        "  # Using GPU\n",
        "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "  model = whisper.load_model(model_size).to(device)\n",
        "  result = model.transcribe(audio_path, language=language, word_timestamps=True)\n",
        "  segments = result['segments']\n",
        "\n",
        "  # print(segments)\n",
        "\n",
        "  all_subtitles = []\n",
        "\n",
        "  for segment in segments:\n",
        "    words = segment['words']\n",
        "    subtitles = []\n",
        "    current_subtitle = []\n",
        "    current_start = None\n",
        "    last_end = None\n",
        "\n",
        "    for word_info in words:\n",
        "      word = word_info['word']\n",
        "      start = word_info['start']\n",
        "      end = word_info['end']\n",
        "\n",
        "      if current_start is None:\n",
        "        current_start = start\n",
        "\n",
        "      current_subtitle.append(word)\n",
        "\n",
        "      if len(current_subtitle) >= words_per_subtitle:\n",
        "        subtitle_text = ' '.join(current_subtitle)\n",
        "        subtitles.append({'start':current_start, 'end':end, 'text':subtitle_text})\n",
        "        current_subtitle = []\n",
        "        current_start = None\n",
        "\n",
        "      last_end = end\n",
        "\n",
        "    if current_subtitle:\n",
        "      subtitle_text = ' '.join(current_subtitle)\n",
        "      subtitles.append({'start': current_start, 'end': last_end, 'text': subtitle_text})\n",
        "\n",
        "    all_subtitles.extend(subtitles)\n",
        "    # print(all_subtitles)\n",
        "\n",
        "  return all_subtitles\n",
        "\n",
        "audio_path = 'output.mp3'\n",
        "subtitles = subtitle_and_timestamps(audio_path)\n",
        "\n",
        "print(subtitles)\n",
        "\n",
        "if subtitles:\n",
        "    for subtitle in subtitles:\n",
        "        print(f\"[{subtitle['start']:.2f} - {subtitle['end']:.2f}] {subtitle['text']}\")\n",
        "else:\n",
        "    print(\"Transcription failed.\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
